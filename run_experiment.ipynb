{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "01fa043e",
   "metadata": {},
   "source": [
    "## Basic Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "74b09b33",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Video opened successfully.\n"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "\n",
    "video_path = \"WhatsApp Video 2025-08-30 at 11.02.13 AM.mp4\"\n",
    "cap = cv2.VideoCapture(video_path)\n",
    "\n",
    "if not cap.isOpened():\n",
    "    print(\"Error: Could not open video.\")\n",
    "else:\n",
    "    print(\"Video opened successfully.\")\n",
    "    # You can add code here to process the video frames\n",
    "    # cap.release() # Don't release yet if you plan to process frames later"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "3ac5172b",
   "metadata": {},
   "outputs": [],
   "source": [
    "while cap.isOpened():\n",
    "    ret, frame = cap.read()\n",
    "    if not ret:\n",
    "        break\n",
    "\n",
    "    # Here we will add code for shuttlecock detection and tracking\n",
    "\n",
    "    # For now, just display the frame\n",
    "    # You might want to resize or process the frame before displaying\n",
    "    cv2.imshow('Frame', frame)\n",
    "\n",
    "    # Press Q on keyboard to  exit\n",
    "    if cv2.waitKey(25) & 0xFF == ord('q'):\n",
    "        break\n",
    "\n",
    "# Release the video capture object\n",
    "cap.release()\n",
    "\n",
    "# Close all the frames\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3c37fb8d",
   "metadata": {},
   "source": [
    "## Main Code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e6c85c2d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Controls:  [S] Save JSON   [Space] Pause/Play   [Q] Quit\n"
     ]
    }
   ],
   "source": [
    "# Cell 0 — Columnar slider UI (2 control columns + 1 preview window)\n",
    "import cv2, numpy as np, json, time\n",
    "from pathlib import Path\n",
    "\n",
    "# --- CONFIG ---\n",
    "video_path = \"WhatsApp Video 2025-08-30 at 11.02.13 AM.mp4\"\n",
    "OUT_DIR = Path(\"outputs\"); OUT_DIR.mkdir(parents=True, exist_ok=True)\n",
    "SAVE_JSON = OUT_DIR / \"mask_params.json\"\n",
    "\n",
    "DOWNSCALE = 1.0\n",
    "DISPLAY_MAX_W = 1400\n",
    "\n",
    "# --- CAPTURE ---\n",
    "cap = cv2.VideoCapture(video_path)\n",
    "if not cap.isOpened():\n",
    "    raise RuntimeError(\"Could not open video (check path).\")\n",
    "\n",
    "# --- WINDOWS (place 2 narrow columns on top, big preview below) ---\n",
    "WIN_PREV = \"Tuner\"\n",
    "WIN_C1   = \"Controls: Color\"\n",
    "WIN_C2   = \"Controls: Levels\"\n",
    "\n",
    "cv2.namedWindow(WIN_PREV, cv2.WINDOW_NORMAL)\n",
    "cv2.namedWindow(WIN_C1,   cv2.WINDOW_NORMAL)\n",
    "cv2.namedWindow(WIN_C2,   cv2.WINDOW_NORMAL)\n",
    "\n",
    "# optional: position windows so they look like columns; tweak to your screen\n",
    "try:\n",
    "    cv2.moveWindow(WIN_C1, 20, 20)\n",
    "    cv2.resizeWindow(WIN_C1, 320, 480)\n",
    "    cv2.moveWindow(WIN_C2, 360, 20)\n",
    "    cv2.resizeWindow(WIN_C2, 320, 480)\n",
    "    cv2.moveWindow(WIN_PREV, 20, 520)\n",
    "    cv2.resizeWindow(WIN_PREV, DISPLAY_MAX_W, 420)\n",
    "except Exception:\n",
    "    pass\n",
    "\n",
    "# --- Trackbars in 2 columns ---\n",
    "# Column 1: color space + HSV or RGB ranges\n",
    "cv2.createTrackbar(\"ColorSpace 0=HSV 1=RGB\", WIN_C1, 0, 1, lambda v: None)\n",
    "\n",
    "# HSV (defaults for yellow/green)\n",
    "for name, init, maxv in [\n",
    "    (\"H low\", 30, 179), (\"H high\", 60, 179),\n",
    "    (\"S low\", 120, 255), (\"S high\", 255, 255),\n",
    "    (\"V low\", 150, 255), (\"V high\", 255, 255),\n",
    "]:\n",
    "    cv2.createTrackbar(name, WIN_C1, init, maxv, lambda v: None)\n",
    "\n",
    "# RGB thresholds\n",
    "for name, init in [\n",
    "    (\"R low\", 0), (\"R high\", 255),\n",
    "    (\"G low\", 180), (\"G high\", 255),\n",
    "    (\"B low\", 0), (\"B high\", 120)\n",
    "]:\n",
    "    cv2.createTrackbar(name, WIN_C1, init, 255, lambda v: None)\n",
    "\n",
    "# Column 2: contrast/brightness + motion fuse\n",
    "cv2.createTrackbar(\"Alpha x100 (contrast)\", WIN_C2, 100, 400, lambda v: None)  # 1.00..4.00\n",
    "cv2.createTrackbar(\"Beta (-100..100)+100\", WIN_C2, 100, 200, lambda v: None)   # 0..200 -> -100..100\n",
    "cv2.createTrackbar(\"Fuse Motion (0/1)\",     WIN_C2, 1,   1,   lambda v: None)\n",
    "\n",
    "bg = cv2.createBackgroundSubtractorMOG2(history=600, varThreshold=32, detectShadows=False)\n",
    "\n",
    "def tb(name, win): \n",
    "    return cv2.getTrackbarPos(name, win)\n",
    "\n",
    "def build_mask(frame_bgr):\n",
    "    # read from both columns\n",
    "    cs    = tb(\"ColorSpace 0=HSV 1=RGB\", WIN_C1)\n",
    "    alpha = tb(\"Alpha x100 (contrast)\", WIN_C2) / 100.0\n",
    "    beta  = tb(\"Beta (-100..100)+100\",  WIN_C2) - 100\n",
    "    fuse  = tb(\"Fuse Motion (0/1)\",     WIN_C2)\n",
    "\n",
    "    adj = cv2.convertScaleAbs(frame_bgr, alpha=alpha, beta=beta)\n",
    "\n",
    "    if cs == 0:  # HSV\n",
    "        hL,hH = tb(\"H low\", WIN_C1),  tb(\"H high\", WIN_C1)\n",
    "        sL,sH = tb(\"S low\", WIN_C1),  tb(\"S high\", WIN_C1)\n",
    "        vL,vH = tb(\"V low\", WIN_C1),  tb(\"V high\", WIN_C1)\n",
    "        hsv = cv2.cvtColor(adj, cv2.COLOR_BGR2HSV)\n",
    "        if hL <= hH:\n",
    "            lower = np.array([hL, sL, vL], np.uint8)\n",
    "            upper = np.array([hH, sH, vH], np.uint8)\n",
    "            mask_color = cv2.inRange(hsv, lower, upper)\n",
    "        else:  # wrap-around\n",
    "            l1,u1 = np.array([0,  sL, vL], np.uint8), np.array([hH, sH, vH], np.uint8)\n",
    "            l2,u2 = np.array([hL, sL, vL], np.uint8), np.array([179,sH, vH], np.uint8)\n",
    "            mask_color = cv2.bitwise_or(cv2.inRange(hsv, l1, u1), cv2.inRange(hsv, l2, u2))\n",
    "    else:       # RGB\n",
    "        rgb = cv2.cvtColor(adj, cv2.COLOR_BGR2RGB)\n",
    "        rL,rH = tb(\"R low\", WIN_C1), tb(\"R high\", WIN_C1)\n",
    "        gL,gH = tb(\"G low\", WIN_C1), tb(\"G high\", WIN_C1)\n",
    "        bL,bH = tb(\"B low\", WIN_C1), tb(\"B high\", WIN_C1)\n",
    "        lower = np.array([rL, gL, bL], np.uint8)\n",
    "        upper = np.array([rH, gH, bH], np.uint8)\n",
    "        mask_color = cv2.inRange(rgb, lower, upper)\n",
    "\n",
    "    # light cleanup\n",
    "    k = cv2.getStructuringElement(cv2.MORPH_ELLIPSE, (3,3))\n",
    "    mask_color = cv2.morphologyEx(mask_color, cv2.MORPH_OPEN, k, iterations=1)\n",
    "    mask_color = cv2.morphologyEx(mask_color, cv2.MORPH_CLOSE, k, iterations=1)\n",
    "\n",
    "    if fuse == 1:\n",
    "        fg = bg.apply(adj)\n",
    "        fg = cv2.medianBlur(fg, 5)\n",
    "        mask = cv2.bitwise_and(mask_color, fg)\n",
    "    else:\n",
    "        mask = mask_color\n",
    "    return adj, mask\n",
    "\n",
    "def make_mosaic(orig_bgr, mask):\n",
    "    mask_bgr = cv2.cvtColor(mask, cv2.COLOR_GRAY2BGR)\n",
    "    masked   = cv2.bitwise_and(orig_bgr, orig_bgr, mask=mask)\n",
    "    row = np.hstack([orig_bgr, mask_bgr, masked])\n",
    "    h,w = row.shape[:2]\n",
    "    if w > DISPLAY_MAX_W:\n",
    "        scale = DISPLAY_MAX_W / w\n",
    "        row = cv2.resize(row, None, fx=scale, fy=scale, interpolation=cv2.INTER_AREA)\n",
    "    return row\n",
    "\n",
    "print(\"Controls:  [S] Save JSON   [Space] Pause/Play   [Q] Quit\")\n",
    "paused, last_frame = False, None\n",
    "\n",
    "try:\n",
    "    while True:\n",
    "        if cv2.getWindowProperty(WIN_PREV, cv2.WND_PROP_VISIBLE) < 1: break\n",
    "\n",
    "        if not paused:\n",
    "            ok, frame = cap.read()\n",
    "            if not ok:\n",
    "                cap.set(cv2.CAP_PROP_POS_FRAMES, 0); continue\n",
    "            if DOWNSCALE != 1.0:\n",
    "                frame = cv2.resize(frame, None, fx=DOWNSCALE, fy=DOWNSCALE, interpolation=cv2.INTER_AREA)\n",
    "            last_frame = frame\n",
    "            adj, mask = build_mask(frame)\n",
    "            cv2.imshow(WIN_PREV, make_mosaic(adj, mask))\n",
    "        else:\n",
    "            if last_frame is not None:\n",
    "                adj, mask = build_mask(last_frame)\n",
    "                cv2.imshow(WIN_PREV, make_mosaic(adj, mask))\n",
    "            time.sleep(0.01)\n",
    "\n",
    "        key = cv2.waitKey(1) & 0xFF\n",
    "        if key == ord('q'): break\n",
    "        if key == ord(' '): paused = not paused\n",
    "        if key == ord('s'):\n",
    "            cs    = tb(\"ColorSpace 0=HSV 1=RGB\", WIN_C1)\n",
    "            alpha = tb(\"Alpha x100 (contrast)\", WIN_C2) / 100.0\n",
    "            beta  = tb(\"Beta (-100..100)+100\",  WIN_C2) - 100\n",
    "            fuse  = tb(\"Fuse Motion (0/1)\",     WIN_C2)\n",
    "            if cs == 0:\n",
    "                color = {\n",
    "                    \"color_space\": \"HSV\",\n",
    "                    \"H_low\": tb(\"H low\", WIN_C1),  \"H_high\": tb(\"H high\", WIN_C1),\n",
    "                    \"S_low\": tb(\"S low\", WIN_C1),  \"S_high\": tb(\"S high\", WIN_C1),\n",
    "                    \"V_low\": tb(\"V low\", WIN_C1),  \"V_high\": tb(\"V high\", WIN_C1),\n",
    "                }\n",
    "            else:\n",
    "                color = {\n",
    "                    \"color_space\": \"RGB\",\n",
    "                    \"R_low\": tb(\"R low\", WIN_C1),  \"R_high\": tb(\"R high\", WIN_C1),\n",
    "                    \"G_low\": tb(\"G low\", WIN_C1),  \"G_high\": tb(\"G high\", WIN_C1),\n",
    "                    \"B_low\": tb(\"B low\", WIN_C1),  \"B_high\": tb(\"B high\", WIN_C1),\n",
    "                }\n",
    "            cfg = {\"color\": color, \"contrast_alpha\": alpha, \"brightness_beta\": beta,\n",
    "                   \"fuse_motion\": int(fuse), \"downscale\": DOWNSCALE}\n",
    "            with open(SAVE_JSON, \"w\") as f:\n",
    "                json.dump(cfg, f, indent=2)\n",
    "            print(f\"Saved → {SAVE_JSON.resolve()}\")\n",
    "finally:\n",
    "    cap.release()\n",
    "    cv2.destroyAllWindows()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "1a03254a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2, json, csv, numpy as np\n",
    "from pathlib import Path\n",
    "\n",
    "SETTINGS_JSON = \"outputs/mask_params.json\"\n",
    "VIDEO_PATH = \"WhatsApp Video 2025-08-30 at 11.02.13 AM.mp4\"\n",
    "\n",
    "OUT = Path(\"outputs\")\n",
    "ANN_DIR  = OUT / \"annotated\"\n",
    "MASK_DIR = OUT / \"masks\"\n",
    "CROP_DIR = OUT / \"crops\"\n",
    "for d in (ANN_DIR, MASK_DIR, CROP_DIR): d.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "def load_settings(p=SETTINGS_JSON):\n",
    "    with open(p, \"r\") as f:\n",
    "        cfg = json.load(f)\n",
    "    cfg.setdefault(\"downscale\", 1.0)\n",
    "    cfg.setdefault(\"contrast_alpha\", 1.0)\n",
    "    cfg.setdefault(\"brightness_beta\", 0)\n",
    "    cfg.setdefault(\"fuse_motion\", 1)\n",
    "    return cfg\n",
    "\n",
    "def build_mask_from_settings(frame_bgr, cfg, bg_subtractor=None):\n",
    "    alpha = float(cfg[\"contrast_alpha\"])\n",
    "    beta  = float(cfg[\"brightness_beta\"])\n",
    "    adj = cv2.convertScaleAbs(frame_bgr, alpha=alpha, beta=beta)\n",
    "\n",
    "    if cfg[\"color\"][\"color_space\"] == \"HSV\":\n",
    "        H_low, H_high = cfg[\"color\"][\"H_low\"], cfg[\"color\"][\"H_high\"]\n",
    "        S_low, S_high = cfg[\"color\"][\"S_low\"], cfg[\"color\"][\"S_high\"]\n",
    "        V_low, V_high = cfg[\"color\"][\"V_low\"], cfg[\"color\"][\"V_high\"]\n",
    "        hsv = cv2.cvtColor(adj, cv2.COLOR_BGR2HSV)\n",
    "        if H_low <= H_high:\n",
    "            lower = np.array([H_low, S_low, V_low], np.uint8)\n",
    "            upper = np.array([H_high, S_high, V_high], np.uint8)\n",
    "            mask_color = cv2.inRange(hsv, lower, upper)\n",
    "        else:\n",
    "            l1,u1 = np.array([0,  S_low, V_low], np.uint8), np.array([H_high, S_high, V_high], np.uint8)\n",
    "            l2,u2 = np.array([H_low, S_low, V_low], np.uint8), np.array([179, S_high, V_high], np.uint8)\n",
    "            mask_color = cv2.bitwise_or(cv2.inRange(hsv, l1, u1), cv2.inRange(hsv, l2, u2))\n",
    "    else:\n",
    "        rgb = cv2.cvtColor(adj, cv2.COLOR_BGR2RGB)\n",
    "        R_low, R_high = cfg[\"color\"][\"R_low\"], cfg[\"color\"][\"R_high\"]\n",
    "        G_low, G_high = cfg[\"color\"][\"G_low\"], cfg[\"color\"][\"G_high\"]\n",
    "        B_low, B_high = cfg[\"color\"][\"B_low\"], cfg[\"color\"][\"B_high\"]\n",
    "        lower = np.array([R_low, G_low, B_low], np.uint8)\n",
    "        upper = np.array([R_high, G_high, B_high], np.uint8)\n",
    "        mask_color = cv2.inRange(rgb, lower, upper)\n",
    "\n",
    "    k = cv2.getStructuringElement(cv2.MORPH_ELLIPSE, (3,3))\n",
    "    mask_color = cv2.morphologyEx(mask_color, cv2.MORPH_OPEN, k, iterations=1)\n",
    "    mask_color = cv2.morphologyEx(mask_color, cv2.MORPH_CLOSE, k, iterations=1)\n",
    "\n",
    "    if int(cfg.get(\"fuse_motion\", 1)) == 1 and bg_subtractor is not None:\n",
    "        fg = bg_subtractor.apply(adj)\n",
    "        fg = cv2.medianBlur(fg, 5)\n",
    "        mask = cv2.bitwise_and(mask_color, fg)\n",
    "    else:\n",
    "        mask = mask_color\n",
    "\n",
    "    return adj, mask\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "bbda4d57",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done.\n",
      "- Video: C:\\Users\\1033249\\OneDrive - Blue Yonder\\documents\\GitHub\\deepLearning_experiment_badmintan\\outputs/isolated_annotated.mp4\n",
      "- CSV:   C:\\Users\\1033249\\OneDrive - Blue Yonder\\documents\\GitHub\\deepLearning_experiment_badmintan\\outputs/detections.csv\n",
      "- Masks: outputs/masks/\n",
      "- Crops: outputs/crops/\n"
     ]
    }
   ],
   "source": [
    "from collections import deque\n",
    "\n",
    "def process_video_with_mask(settings_path=SETTINGS_JSON,\n",
    "                            video_path=VIDEO_PATH,\n",
    "                            save_video=True,\n",
    "                            draw_path=True,\n",
    "                            trail_maxlen=10000,\n",
    "                            # prediction params:\n",
    "                            history_len=5,          # use last K measured points\n",
    "                            enforce_horizontal=True,# keep y flat at median of K\n",
    "                            dx_clip_px=50,          # cap horizontal step per miss\n",
    "                            max_predict_frames=45): # max coasting length\n",
    "    cfg = load_settings(settings_path)\n",
    "\n",
    "    cap = cv2.VideoCapture(video_path)\n",
    "    if not cap.isOpened():\n",
    "        raise RuntimeError(\"Could not open video\")\n",
    "\n",
    "    DS = float(cfg.get(\"downscale\", 1.0))\n",
    "    bg = cv2.createBackgroundSubtractorMOG2(history=600, varThreshold=32, detectShadows=False) \\\n",
    "         if int(cfg.get(\"fuse_motion\", 1)) == 1 else None\n",
    "\n",
    "    OUT.mkdir(exist_ok=True, parents=True)\n",
    "    csv_path = OUT / \"detections.csv\"\n",
    "    with open(csv_path, \"w\", newline=\"\") as f:\n",
    "        csv.writer(f).writerow([\"frame\",\"x\",\"y\",\"w\",\"h\",\"source\"])  # measured|predicted\n",
    "\n",
    "    writer = None\n",
    "    trail = deque(maxlen=trail_maxlen)\n",
    "    measured_hist = deque(maxlen=history_len)\n",
    "    last_pt = None\n",
    "    miss_streak = 0\n",
    "\n",
    "    frame_idx = 0\n",
    "    while True:\n",
    "        ret, frame = cap.read()\n",
    "        if not ret: break\n",
    "        frame_idx += 1\n",
    "\n",
    "        frame_ds = cv2.resize(frame, None, fx=DS, fy=DS, interpolation=cv2.INTER_AREA) if DS != 1.0 else frame\n",
    "        adj, mask = build_mask_from_settings(frame_ds, cfg, bg)\n",
    "\n",
    "        cnts = cv2.findContours(mask, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n",
    "        cnts = cnts[0] if len(cnts)==2 else cnts[1]\n",
    "        H, W = adj.shape[:2]\n",
    "\n",
    "        # pick best contour\n",
    "        best = None\n",
    "        best_score = -1.0\n",
    "        for c in cnts:\n",
    "            area = cv2.contourArea(c)\n",
    "            if area < 8: continue\n",
    "            M = cv2.moments(c)\n",
    "            if M[\"m00\"] == 0: continue\n",
    "            cx, cy = int(M[\"m10\"]/M[\"m00\"]), int(M[\"m01\"]/M[\"m00\"])\n",
    "            x,y,w,h = cv2.boundingRect(c)\n",
    "            p = cv2.arcLength(c, True)\n",
    "            circ = (4*np.pi*area/(p*p)) if p>0 else 0\n",
    "            score = area*0.15 + circ*20\n",
    "            if score > best_score:\n",
    "                best_score = score\n",
    "                best = (cx, cy, x, y, w, h)\n",
    "\n",
    "        vis = adj.copy()\n",
    "\n",
    "        if best is not None:\n",
    "            cx, cy, x, y, w, h = best\n",
    "            last_pt = (cx, cy)\n",
    "            if draw_path:\n",
    "                trail.append(last_pt)\n",
    "            measured_hist.append((cx, cy))\n",
    "            miss_streak = 0\n",
    "\n",
    "            cv2.rectangle(vis, (x,y), (x+w,y+h), (0,255,0), 2)\n",
    "            cv2.circle(vis, (cx,cy), 4, (0,0,255), -1)\n",
    "\n",
    "            scale_back = 1.0 / DS\n",
    "            with open(csv_path, \"a\", newline=\"\") as f:\n",
    "                csv.writer(f).writerow([frame_idx,\n",
    "                                        int(x*scale_back), int(y*scale_back),\n",
    "                                        int(w*scale_back), int(h*scale_back),\n",
    "                                        \"measured\"])\n",
    "        else:\n",
    "            # predict horizontally using last K measured points\n",
    "            miss_streak += 1\n",
    "            if last_pt is None or len(measured_hist) < 2:\n",
    "                if last_pt is not None and draw_path:\n",
    "                    trail.append(last_pt)\n",
    "                with open(csv_path, \"a\", newline=\"\") as f:\n",
    "                    csv.writer(f).writerow([frame_idx, 0, 0, 0, 0, \"predicted\"])\n",
    "            else:\n",
    "                xs = [p[0] for p in measured_hist]\n",
    "                ys = [p[1] for p in measured_hist]\n",
    "                dxs = [xs[i+1]-xs[i] for i in range(len(xs)-1)]\n",
    "                dys = [ys[i+1]-ys[i] for i in range(len(ys)-1)]\n",
    "\n",
    "                med_dx = float(np.median(dxs)) if dxs else 0.0\n",
    "                med_dy = float(np.median(dys)) if dys else 0.0\n",
    "\n",
    "                if enforce_horizontal:\n",
    "                    next_y = int(np.median(ys))  # lock to median height\n",
    "                    step_x = int(np.clip(med_dx, -dx_clip_px, dx_clip_px))\n",
    "                    if step_x == 0:\n",
    "                        step_x = 1 if (dxs and dxs[-1] >= 0) else -1\n",
    "                    next_x = int(np.clip(last_pt[0] + step_x, 0, W-1))\n",
    "                else:\n",
    "                    step_x = int(np.clip(med_dx, -dx_clip_px, dx_clip_px))\n",
    "                    step_y = int(np.clip(med_dy*0.2, -10, 10))\n",
    "                    next_x = int(np.clip(last_pt[0] + step_x, 0, W-1))\n",
    "                    next_y = int(np.clip(last_pt[1] + step_y, 0, H-1))\n",
    "\n",
    "                last_pt = (next_x, next_y)\n",
    "                if draw_path:\n",
    "                    trail.append(last_pt)\n",
    "\n",
    "                cv2.circle(vis, last_pt, 4, (0,165,255), -1)  # orange dot for predicted\n",
    "\n",
    "                with open(csv_path, \"a\", newline=\"\") as f:\n",
    "                    csv.writer(f).writerow([frame_idx, 0, 0, 0, 0, \"predicted\"])\n",
    "\n",
    "                if miss_streak > max_predict_frames:\n",
    "                    pass  # stop drifting forever\n",
    "\n",
    "        # draw full trail each frame\n",
    "        if draw_path and len(trail) > 1:\n",
    "            for i in range(1, len(trail)):\n",
    "                cv2.line(vis, trail[i-1], trail[i], (0,255,0), 2)\n",
    "\n",
    "        cv2.putText(vis, f\"Frame {frame_idx}\", (10,26),\n",
    "                    cv2.FONT_HERSHEY_SIMPLEX, 0.7, (255,255,255), 2, cv2.LINE_AA)\n",
    "\n",
    "        # writer\n",
    "        if save_video and writer is None:\n",
    "            fourcc = cv2.VideoWriter_fourcc(*\"mp4v\")\n",
    "            fps = cap.get(cv2.CAP_PROP_FPS) or 30\n",
    "            writer = cv2.VideoWriter(str(OUT / \"isolated_annotated.mp4\"), fourcc, fps, (vis.shape[1], vis.shape[0]))\n",
    "        if writer is not None:\n",
    "            writer.write(vis)\n",
    "\n",
    "        # preview (press 'q' to stop)\n",
    "        cv2.imshow(\"Isolated (annotated)\", vis)\n",
    "        if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "            break\n",
    "\n",
    "    cap.release()\n",
    "    if writer is not None:\n",
    "        writer.release()\n",
    "    cv2.destroyAllWindows()\n",
    "\n",
    "    print(f\"Done.\\n- Video: {OUT.resolve()}/isolated_annotated.mp4\\n- CSV:   {OUT.resolve()}/detections.csv\\n- Masks: outputs/masks/\\n- Crops: outputs/crops/\")\n",
    "\n",
    "# Run it\n",
    "process_video_with_mask()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "439e08ad",
   "metadata": {},
   "source": [
    "## Advance Code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "ac93bf57",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2, numpy as np, json\n",
    "from pathlib import Path\n",
    "import tkinter as tk\n",
    "from tkinter import ttk\n",
    "from PIL import Image, ImageTk\n",
    "\n",
    "# ---------- Config ----------\n",
    "video_path = \"WhatsApp Video 2025-08-30 at 11.02.13 AM.mp4\"\n",
    "OUT_DIR = Path(\"outputs\"); OUT_DIR.mkdir(parents=True, exist_ok=True)\n",
    "SAVE_JSON = OUT_DIR / \"mask_params.json\"\n",
    "\n",
    "DOWNSCALE = 1.0          # keep 1.0 for tiny shuttle\n",
    "PREVIEW_MAX_W = 1280     # preview content caps (window can be larger)\n",
    "PREVIEW_MAX_H = 720\n",
    "\n",
    "# ---------- OpenCV capture ----------\n",
    "cap = cv2.VideoCapture(video_path)\n",
    "if not cap.isOpened():\n",
    "    raise RuntimeError(\"Could not open video (check path).\")\n",
    "\n",
    "bg = cv2.createBackgroundSubtractorMOG2(history=600, varThreshold=32, detectShadows=False)\n",
    "\n",
    "# ---------- Tk roots: two separate windows ----------\n",
    "root = tk.Tk()\n",
    "root.withdraw()  # hide implicit root\n",
    "\n",
    "w_preview = tk.Toplevel()\n",
    "w_preview.title(\"Shuttle Preview\")\n",
    "w_preview.geometry(\"900x520+80+60\")\n",
    "w_preview.minsize(480, 320)\n",
    "\n",
    "w_controls = tk.Toplevel()\n",
    "w_controls.title(\"Shuttle Controls\")\n",
    "w_controls.geometry(\"540x640+1000+60\")\n",
    "w_controls.minsize(520, 620)\n",
    "\n",
    "# ---- running flag so the cell exits cleanly on close ----\n",
    "running = True\n",
    "\n",
    "# ----- PREVIEW WINDOW -----\n",
    "preview_canvas = tk.Label(w_preview, bg=\"#111\")\n",
    "preview_canvas.pack(fill=\"both\", expand=True)\n",
    "\n",
    "# ----- CONTROLS WINDOW -----\n",
    "controls_frame = ttk.Frame(w_controls, padding=8)\n",
    "controls_frame.pack(fill=\"both\", expand=True)\n",
    "\n",
    "def make_labeled_scale(parent, text, var, frm, to, row, col=0, length=220, fmt=\"{:d}\"):\n",
    "    ttk.Label(parent, text=text).grid(row=row, column=col, sticky=\"w\")\n",
    "    s = ttk.Scale(parent, from_=frm, to=to, orient=\"horizontal\",\n",
    "                  variable=var, length=length)\n",
    "    s.grid(row=row, column=col+1, padx=6, pady=3, sticky=\"ew\")\n",
    "    val = ttk.Label(parent, width=6)\n",
    "    val.grid(row=row, column=col+2, sticky=\"w\")\n",
    "    def _upd(*_):\n",
    "        v = var.get()\n",
    "        try: val.config(text=fmt.format(int(round(v))))\n",
    "        except Exception: val.config(text=fmt.format(float(v)))\n",
    "    var.trace_add(\"write\", _upd); _upd()\n",
    "    return s\n",
    "\n",
    "# groups\n",
    "col_left  = ttk.LabelFrame(controls_frame, text=\"Color Space & Ranges\", padding=8)\n",
    "col_right = ttk.LabelFrame(controls_frame, text=\"Levels & Options\", padding=8)\n",
    "col_left.grid(row=0, column=0, sticky=\"n\", padx=(0,8))\n",
    "col_right.grid(row=0, column=1, sticky=\"n\")\n",
    "\n",
    "view_group = ttk.LabelFrame(controls_frame, text=\"Preview\", padding=8)\n",
    "view_group.grid(row=1, column=0, columnspan=2, sticky=\"ew\", pady=(8,0))\n",
    "\n",
    "# --- view & zoom ---\n",
    "view_mode = tk.StringVar(value=\"Original\")\n",
    "for i, name in enumerate((\"Original\",\"Mask\",\"Masked\",\"Mosaic\")):\n",
    "    ttk.Radiobutton(view_group, text=name, variable=view_mode, value=name).grid(row=0, column=i, sticky=\"w\")\n",
    "zoom_var = tk.IntVar(value=100)\n",
    "ttk.Label(view_group, text=\"Zoom %\").grid(row=1, column=0, sticky=\"w\", pady=(6,0))\n",
    "make_labeled_scale(view_group, \" \", zoom_var, 50, 200, row=1, col=1, length=260, fmt=\"{:d}\")\n",
    "\n",
    "# --- color space toggle ---\n",
    "color_space = tk.StringVar(value=\"HSV\")\n",
    "ttk.Radiobutton(col_left, text=\"HSV\", variable=color_space, value=\"HSV\").grid(row=0, column=0, sticky=\"w\")\n",
    "ttk.Radiobutton(col_left, text=\"RGB\", variable=color_space, value=\"RGB\").grid(row=0, column=1, sticky=\"w\")\n",
    "\n",
    "# --- HSV sliders ---\n",
    "H_low  = tk.IntVar(value=30);  H_high = tk.IntVar(value=60)\n",
    "S_low  = tk.IntVar(value=120); S_high = tk.IntVar(value=255)\n",
    "V_low  = tk.IntVar(value=150); V_high = tk.IntVar(value=255)\n",
    "make_labeled_scale(col_left, \"H low\",  H_low,  0, 179, 1)\n",
    "make_labeled_scale(col_left, \"H high\", H_high, 0, 179, 2)\n",
    "make_labeled_scale(col_left, \"S low\",  S_low,  0, 255, 3)\n",
    "make_labeled_scale(col_left, \"S high\", S_high, 0, 255, 4)\n",
    "make_labeled_scale(col_left, \"V low\",  V_low,  0, 255, 5)\n",
    "make_labeled_scale(col_left, \"V high\", V_high, 0, 255, 6)\n",
    "\n",
    "# --- RGB sliders ---\n",
    "R_low  = tk.IntVar(value=0);   R_high = tk.IntVar(value=255)\n",
    "G_low  = tk.IntVar(value=180); G_high = tk.IntVar(value=255)\n",
    "B_low  = tk.IntVar(value=0);   B_high = tk.IntVar(value=120)\n",
    "make_labeled_scale(col_left, \"R low\",  R_low,  0, 255, 7)\n",
    "make_labeled_scale(col_left, \"R high\", R_high, 0, 255, 8)\n",
    "make_labeled_scale(col_left, \"G low\",  G_low,  0, 255, 9)\n",
    "make_labeled_scale(col_left, \"G high\", G_high, 0, 255,10)\n",
    "make_labeled_scale(col_left, \"B low\",  B_low,  0, 255,11)\n",
    "make_labeled_scale(col_left, \"B high\", B_high, 0, 255,12)\n",
    "\n",
    "# --- levels & options ---\n",
    "alpha_var = tk.DoubleVar(value=1.00)\n",
    "beta_var  = tk.IntVar(value=0)\n",
    "fuse_motion = tk.IntVar(value=1)\n",
    "\n",
    "make_labeled_scale(col_right, \"Contrast (alpha)\", alpha_var, 0.5, 4.0, 0, fmt=\"{:.2f}\")\n",
    "make_labeled_scale(col_right, \"Brightness (beta)\", beta_var, -100, 100, 1, fmt=\"{:d}\")\n",
    "ttk.Checkbutton(col_right, text=\"Fuse Motion (MOG2)\", variable=fuse_motion).grid(row=2, column=0, columnspan=3, sticky=\"w\", pady=(6,2))\n",
    "\n",
    "def save_settings():\n",
    "    if color_space.get() == \"HSV\":\n",
    "        color = {\"color_space\":\"HSV\",\n",
    "                 \"H_low\":H_low.get(), \"H_high\":H_high.get(),\n",
    "                 \"S_low\":S_low.get(), \"S_high\":S_high.get(),\n",
    "                 \"V_low\":V_low.get(), \"V_high\":V_high.get()}\n",
    "    else:\n",
    "        color = {\"color_space\":\"RGB\",\n",
    "                 \"R_low\":R_low.get(), \"R_high\":R_high.get(),\n",
    "                 \"G_low\":G_low.get(), \"G_high\":G_high.get(),\n",
    "                 \"B_low\":B_low.get(), \"B_high\":B_high.get()}\n",
    "    cfg = {\"color\":color,\n",
    "           \"contrast_alpha\":float(alpha_var.get()),\n",
    "           \"brightness_beta\":int(beta_var.get()),\n",
    "           \"fuse_motion\":int(fuse_motion.get()),\n",
    "           \"downscale\":DOWNSCALE}\n",
    "    with open(SAVE_JSON, \"w\") as f:\n",
    "        json.dump(cfg, f, indent=2)\n",
    "    status_var.set(f\"Saved → {SAVE_JSON.resolve()}\")\n",
    "\n",
    "ttk.Button(col_right, text=\"Save Settings\", command=save_settings).grid(row=3, column=0, columnspan=3, pady=10, sticky=\"ew\")\n",
    "status_var = tk.StringVar(value=\"Pick a view, tune sliders, then Save Settings\")\n",
    "ttk.Label(col_right, textvariable=status_var, wraplength=320, foreground=\"#0a6\").grid(row=4, column=0, columnspan=3, sticky=\"w\")\n",
    "\n",
    "# ---------- Mask + preview helpers ----------\n",
    "def build_mask(frame_bgr):\n",
    "    alpha = float(alpha_var.get())\n",
    "    beta  = int(beta_var.get())\n",
    "    adj = cv2.convertScaleAbs(frame_bgr, alpha=alpha, beta=beta)\n",
    "\n",
    "    if color_space.get() == \"HSV\":\n",
    "        hL,hH = int(H_low.get()),  int(H_high.get())\n",
    "        sL,sH = int(S_low.get()),  int(S_high.get())\n",
    "        vL,vH = int(V_low.get()),  int(V_high.get())\n",
    "        hsv = cv2.cvtColor(adj, cv2.COLOR_BGR2HSV)\n",
    "        if hL <= hH:\n",
    "            lower = np.array([hL, sL, vL], np.uint8)\n",
    "            upper = np.array([hH, sH, vH], np.uint8)\n",
    "            mask_color = cv2.inRange(hsv, lower, upper)\n",
    "        else:\n",
    "            l1,u1 = np.array([0,  sL, vL], np.uint8), np.array([hH, sH, vH], np.uint8)\n",
    "            l2,u2 = np.array([hL, sL, vL], np.uint8), np.array([179, sH, vH], np.uint8)\n",
    "            mask_color = cv2.bitwise_or(cv2.inRange(hsv, l1, u1), cv2.inRange(hsv, l2, u2))\n",
    "    else:\n",
    "        rgb = cv2.cvtColor(adj, cv2.COLOR_BGR2RGB)\n",
    "        lower = np.array([R_low.get(), G_low.get(), B_low.get()], np.uint8)\n",
    "        upper = np.array([R_high.get(), G_high.get(), B_high.get()], np.uint8)\n",
    "        mask_color = cv2.inRange(rgb, lower, upper)\n",
    "\n",
    "    k = cv2.getStructuringElement(cv2.MORPH_ELLIPSE, (3,3))\n",
    "    mask_color = cv2.morphologyEx(mask_color, cv2.MORPH_OPEN, k, iterations=1)\n",
    "    mask_color = cv2.morphologyEx(mask_color, cv2.MORPH_CLOSE, k, iterations=1)\n",
    "\n",
    "    if fuse_motion.get() == 1:\n",
    "        fg = bg.apply(adj)\n",
    "        fg = cv2.medianBlur(fg, 5)\n",
    "        mask = cv2.bitwise_and(mask_color, fg)\n",
    "    else:\n",
    "        mask = mask_color\n",
    "    return adj, mask\n",
    "\n",
    "def fit_scale(w, h, max_w, max_h, zoom_pct):\n",
    "    z = max(0.01, zoom_pct/100.0)\n",
    "    w2, h2 = int(w*z), int(h*z)\n",
    "    s = min(max_w/max(w2,1), max_h/max(h2,1), 1.0)\n",
    "    return z*s\n",
    "\n",
    "def render_view(adj, mask, mode):\n",
    "    if mode == \"Original\":\n",
    "        view = adj\n",
    "    elif mode == \"Mask\":\n",
    "        view = cv2.cvtColor(mask, cv2.COLOR_GRAY2BGR)\n",
    "    elif mode == \"Masked\":\n",
    "        view = cv2.bitwise_and(adj, adj, mask=mask)\n",
    "    else:  # Mosaic\n",
    "        mask_bgr = cv2.cvtColor(mask, cv2.COLOR_GRAY2BGR)\n",
    "        masked   = cv2.bitwise_and(adj, adj, mask=mask)\n",
    "        view = np.hstack([adj, mask_bgr, masked])\n",
    "    return view\n",
    "\n",
    "def update_preview():\n",
    "    if not running:\n",
    "        return  # stop scheduling when closing\n",
    "\n",
    "    w_preview.update_idletasks()\n",
    "    max_w = max(200, w_preview.winfo_width()-16)\n",
    "    max_h = max(150, w_preview.winfo_height()-16)\n",
    "\n",
    "    ok, frame = cap.read()\n",
    "    if not ok or not running:\n",
    "        if running:\n",
    "            cap.set(cv2.CAP_PROP_POS_FRAMES, 0)\n",
    "            w_preview.after(10, update_preview)\n",
    "        return\n",
    "\n",
    "    if DOWNSCALE != 1.0:\n",
    "        frame = cv2.resize(frame, None, fx=DOWNSCALE, fy=DOWNSCALE, interpolation=cv2.INTER_AREA)\n",
    "\n",
    "    adj, mask = build_mask(frame)\n",
    "    view = render_view(adj, mask, view_mode.get())\n",
    "\n",
    "    # cap size by both the window and global caps\n",
    "    max_w = min(max_w, PREVIEW_MAX_W)\n",
    "    max_h = min(max_h, PREVIEW_MAX_H)\n",
    "    h, w = view.shape[:2]\n",
    "    scale = fit_scale(w, h, max_w, max_h, zoom_var.get())\n",
    "    if abs(scale-1.0) > 1e-6:\n",
    "        view = cv2.resize(view, (int(w*scale), int(h*scale)), interpolation=cv2.INTER_AREA)\n",
    "\n",
    "    view_rgb = cv2.cvtColor(view, cv2.COLOR_BGR2RGB)\n",
    "    im = Image.fromarray(view_rgb)\n",
    "    tk_img = ImageTk.PhotoImage(image=im)\n",
    "    preview_canvas.configure(image=tk_img)\n",
    "    preview_canvas.image = tk_img\n",
    "\n",
    "    if running:\n",
    "        w_preview.after(1, update_preview)\n",
    "\n",
    "def on_close_all():\n",
    "    global running\n",
    "    running = False\n",
    "    try: cap.release()\n",
    "    except Exception: pass\n",
    "    for w in (w_preview, w_controls):\n",
    "        try: w.destroy()\n",
    "        except Exception: pass\n",
    "    try:\n",
    "        root.quit()      # stop mainloop\n",
    "        root.destroy()   # kill hidden root\n",
    "    except Exception:\n",
    "        pass\n",
    "\n",
    "w_preview.protocol(\"WM_DELETE_WINDOW\", on_close_all)\n",
    "w_controls.protocol(\"WM_DELETE_WINDOW\", on_close_all)\n",
    "\n",
    "update_preview()\n",
    "tk.mainloop()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "ac1a5d96",
   "metadata": {},
   "outputs": [],
   "source": [
    "# CELL 1 — helpers\n",
    "import cv2, json, csv, numpy as np\n",
    "from pathlib import Path\n",
    "\n",
    "SETTINGS_JSON = \"outputs/mask_params.json\"\n",
    "VIDEO_PATH    = \"WhatsApp Video 2025-08-30 at 11.02.13 AM.mp4\"\n",
    "\n",
    "# outputs\n",
    "OUT      = Path(\"outputs\"); OUT.mkdir(parents=True, exist_ok=True)\n",
    "MASK_DIR = OUT / \"masks\";   MASK_DIR.mkdir(exist_ok=True)\n",
    "CROP_DIR = OUT / \"crops\";   CROP_DIR.mkdir(exist_ok=True)\n",
    "\n",
    "def load_settings(p=SETTINGS_JSON):\n",
    "    with open(p, \"r\") as f:\n",
    "        cfg = json.load(f)\n",
    "    cfg.setdefault(\"downscale\", 1.0)\n",
    "    cfg.setdefault(\"contrast_alpha\", 1.0)\n",
    "    cfg.setdefault(\"brightness_beta\", 0)\n",
    "    cfg.setdefault(\"fuse_motion\", 1)\n",
    "    return cfg\n",
    "\n",
    "def build_mask_from_settings(frame_bgr, cfg, bg_subtractor=None):\n",
    "    \"\"\"Return (adjusted_frame, binary_mask) using your saved thresholds.\"\"\"\n",
    "    alpha = float(cfg[\"contrast_alpha\"])\n",
    "    beta  = float(cfg[\"brightness_beta\"])\n",
    "    adj = cv2.convertScaleAbs(frame_bgr, alpha=alpha, beta=beta)\n",
    "\n",
    "    if cfg[\"color\"][\"color_space\"] == \"HSV\":\n",
    "        H_low, H_high = cfg[\"color\"][\"H_low\"],  cfg[\"color\"][\"H_high\"]\n",
    "        S_low, S_high = cfg[\"color\"][\"S_low\"],  cfg[\"color\"][\"S_high\"]\n",
    "        V_low, V_high = cfg[\"color\"][\"V_low\"],  cfg[\"color\"][\"V_high\"]\n",
    "        hsv = cv2.cvtColor(adj, cv2.COLOR_BGR2HSV)\n",
    "        if H_low <= H_high:\n",
    "            lower = np.array([H_low, S_low, V_low], np.uint8)\n",
    "            upper = np.array([H_high, S_high, V_high], np.uint8)\n",
    "            mask_color = cv2.inRange(hsv, lower, upper)\n",
    "        else:\n",
    "            l1,u1 = np.array([0,   S_low, V_low], np.uint8), np.array([H_high, S_high, V_high], np.uint8)\n",
    "            l2,u2 = np.array([H_low, S_low, V_low], np.uint8), np.array([179,  S_high, V_high], np.uint8)\n",
    "            mask_color = cv2.bitwise_or(cv2.inRange(hsv, l1, u1), cv2.inRange(hsv, l2, u2))\n",
    "    else:\n",
    "        rgb = cv2.cvtColor(adj, cv2.COLOR_BGR2RGB)\n",
    "        R_low, R_high = cfg[\"color\"][\"R_low\"], cfg[\"color\"][\"R_high\"]\n",
    "        G_low, G_high = cfg[\"color\"][\"G_low\"], cfg[\"color\"][\"G_high\"]\n",
    "        B_low, B_high = cfg[\"color\"][\"B_low\"], cfg[\"color\"][\"B_high\"]\n",
    "        lower = np.array([R_low, G_low, B_low], np.uint8)\n",
    "        upper = np.array([R_high, G_high, B_high], np.uint8)\n",
    "        mask_color = cv2.inRange(rgb, lower, upper)\n",
    "\n",
    "    k = cv2.getStructuringElement(cv2.MORPH_ELLIPSE, (3,3))\n",
    "    mask_color = cv2.morphologyEx(mask_color, cv2.MORPH_OPEN, k, iterations=1)\n",
    "    mask_color = cv2.morphologyEx(mask_color, cv2.MORPH_CLOSE, k, iterations=1)\n",
    "\n",
    "    if int(cfg.get(\"fuse_motion\", 1)) == 1 and bg_subtractor is not None:\n",
    "        fg = bg_subtractor.apply(adj)\n",
    "        fg = cv2.medianBlur(fg, 5)\n",
    "        mask = cv2.bitwise_and(mask_color, fg)\n",
    "    else:\n",
    "        mask = mask_color\n",
    "\n",
    "    return adj, mask\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "828d931e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done.\n",
      "- Video (original size): C:\\Users\\1033249\\OneDrive - Blue Yonder\\documents\\GitHub\\deepLearning_experiment_badmintan\\outputs/isolated_annotated.mp4 @ 9.49 FPS\n",
      "- CSV: C:\\Users\\1033249\\OneDrive - Blue Yonder\\documents\\GitHub\\deepLearning_experiment_badmintan\\outputs/detections.csv\n"
     ]
    }
   ],
   "source": [
    "# CELL 2 — robust left/right during misses: keep last measured velocity\n",
    "from collections import deque\n",
    "import numpy as np, csv, cv2\n",
    "\n",
    "def _estimate_fps(video_path, fallback=30.0):\n",
    "    cap = cv2.VideoCapture(video_path)\n",
    "    if not cap.isOpened(): return fallback\n",
    "    fps = cap.get(cv2.CAP_PROP_FPS) or 0\n",
    "    cap.release()\n",
    "    return fps if 1.0 <= fps <= 240.0 else fallback\n",
    "\n",
    "def process_video_with_mask(settings_path=SETTINGS_JSON,\n",
    "                            video_path=VIDEO_PATH,\n",
    "                            save_video=True,\n",
    "                            draw_path=True,\n",
    "                            trail_maxlen=20000,\n",
    "                            # velocity estimation window (measured-only):\n",
    "                            vel_k=5,                  # use last K measured frames for velocity\n",
    "                            vel_decay=0.98,           # decay when coasting (1.0 = no decay)\n",
    "                            enforce_horizontal=True,  # lock Y during misses\n",
    "                            max_step_px=80,           # clamp |Δx| per frame in DS px\n",
    "                            min_step_px=1,            # min |Δx| when coasting\n",
    "                            max_predict_frames=90):   # don’t coast forever\n",
    "    cfg = load_settings(settings_path)\n",
    "\n",
    "    cap = cv2.VideoCapture(video_path)\n",
    "    if not cap.isOpened():\n",
    "        raise RuntimeError(\"Could not open video\")\n",
    "\n",
    "    DS = float(cfg.get(\"downscale\", 1.0)) or 1.0\n",
    "    scale_back = 1.0 / DS\n",
    "    fps_out = _estimate_fps(video_path)\n",
    "\n",
    "    # enable motion fusion only for mask-making\n",
    "    bg = cv2.createBackgroundSubtractorMOG2(history=600, varThreshold=32, detectShadows=False) \\\n",
    "         if int(cfg.get(\"fuse_motion\", 1)) == 1 else None\n",
    "\n",
    "    # outputs\n",
    "    OUT.mkdir(exist_ok=True, parents=True)\n",
    "    csv_path = OUT / \"detections.csv\"\n",
    "    with open(csv_path, \"w\", newline=\"\") as f:\n",
    "        csv.writer(f).writerow([\"frame\",\"x\",\"y\",\"w\",\"h\",\"source\"])  # ORIGINAL coords\n",
    "\n",
    "    writer = None\n",
    "\n",
    "    # trail drawn on ORIGINAL coords\n",
    "    trail_orig = deque(maxlen=trail_maxlen)\n",
    "\n",
    "    # keep only MEASURED centers (DS coords) + their absolute frame indices for velocity fit\n",
    "    meas_pts_ds = deque(maxlen=max(vel_k, 6))     # [(frame_idx, cx_ds, cy_ds), ...]\n",
    "    last_used_ds = None                           # last point in DS we advanced from (measured or predicted)\n",
    "    vx_ds = 0.0                                   # current horizontal velocity (DS px/frame), signed\n",
    "    miss_streak = 0\n",
    "    frame_idx = 0\n",
    "\n",
    "    while True:\n",
    "        ret, frame_orig = cap.read()\n",
    "        if not ret:\n",
    "            break\n",
    "        frame_idx += 1\n",
    "\n",
    "        H0, W0 = frame_orig.shape[:2]\n",
    "        frame_ds = cv2.resize(frame_orig, None, fx=DS, fy=DS, interpolation=cv2.INTER_AREA) if DS != 1.0 else frame_orig\n",
    "\n",
    "        adj_ds, mask = build_mask_from_settings(frame_ds, cfg, bg)\n",
    "        cnts = cv2.findContours(mask, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n",
    "        cnts = cnts[0] if len(cnts)==2 else cnts[1]\n",
    "\n",
    "        # choose best contour (small + roundish)\n",
    "        best = None; best_score = -1.0\n",
    "        for c in cnts:\n",
    "            area = cv2.contourArea(c)\n",
    "            if area < 8: continue\n",
    "            M = cv2.moments(c)\n",
    "            if M[\"m00\"] == 0: continue\n",
    "            cx, cy = int(M[\"m10\"]/M[\"m00\"]), int(M[\"m01\"]/M[\"m00\"])\n",
    "            x,y,w,h = cv2.boundingRect(c)\n",
    "            p = cv2.arcLength(c, True)\n",
    "            circ = (4*np.pi*area/(p*p)) if p>0 else 0\n",
    "            score = area*0.15 + circ*20\n",
    "            if score > best_score:\n",
    "                best_score = score\n",
    "                best = (cx, cy, x, y, w, h)\n",
    "\n",
    "        vis = frame_orig.copy()\n",
    "\n",
    "        if best is not None:\n",
    "            # ------ MEASURED ------\n",
    "            cx, cy, x, y, w, h = best\n",
    "            miss_streak = 0\n",
    "            last_used_ds = (cx, cy)\n",
    "\n",
    "            # append measured point for velocity fit\n",
    "            meas_pts_ds.append((frame_idx, cx, cy))\n",
    "\n",
    "            # update velocity using last vel_k measured points\n",
    "            if len(meas_pts_ds) >= 2:\n",
    "                recent = list(meas_pts_ds)[-vel_k:]\n",
    "                t = np.array([p[0] for p in recent], dtype=np.float32)\n",
    "                xarr = np.array([p[1] for p in recent], dtype=np.float32)\n",
    "                # robust small window linear fit: x ≈ a*t + b -> a is vx\n",
    "                # center times to reduce numeric issues\n",
    "                t0 = t.mean()\n",
    "                denom = np.sum((t - t0)**2)\n",
    "                if denom > 0:\n",
    "                    a = np.sum((t - t0) * (xarr - xarr.mean())) / denom\n",
    "                    vx_ds = float(np.clip(a, -max_step_px, max_step_px))\n",
    "                # if velocity is tiny but the last step was not, keep last vx_ds\n",
    "                if abs(vx_ds) < 0.25 and len(recent) >= 2:\n",
    "                    dx_last = recent[-1][1] - recent[-2][1]\n",
    "                    if abs(dx_last) >= 1:\n",
    "                        vx_ds = float(np.clip(dx_last, -max_step_px, max_step_px))\n",
    "\n",
    "            # map to ORIGINAL and draw\n",
    "            X = int(round(x * scale_back)); Y = int(round(y * scale_back))\n",
    "            Wb = int(round(w * scale_back)); Hb = int(round(h * scale_back))\n",
    "            Cx = int(round(cx * scale_back)); Cy = int(round(cy * scale_back))\n",
    "\n",
    "            if draw_path:\n",
    "                trail_orig.append((Cx, Cy))\n",
    "            cv2.rectangle(vis, (X, Y), (X+Wb, Y+Hb), (0,255,0), 2)\n",
    "            cv2.circle(vis, (Cx, Cy), 4, (0,0,255), -1)\n",
    "\n",
    "            with open(csv_path, \"a\", newline=\"\") as f:\n",
    "                csv.writer(f).writerow([frame_idx, X, Y, Wb, Hb, \"measured\"])\n",
    "\n",
    "        else:\n",
    "            # ------ PREDICT (use last measured velocity strictly) ------\n",
    "            miss_streak += 1\n",
    "            if last_used_ds is None or len(meas_pts_ds) < 2:\n",
    "                # hold trail steady until we have velocity\n",
    "                if len(trail_orig) > 0 and draw_path:\n",
    "                    trail_orig.append(trail_orig[-1])\n",
    "                with open(csv_path, \"a\", newline=\"\") as f:\n",
    "                    csv.writer(f).writerow([frame_idx, 0, 0, 0, 0, \"predicted\"])\n",
    "            else:\n",
    "                # speed = last vx_ds (signed). If zero, fall back to last measured step.\n",
    "                if abs(vx_ds) < 0.25:\n",
    "                    # try last instantaneous step from the last two measured points\n",
    "                    p2, p1 = meas_pts_ds[-1], meas_pts_ds[-2]\n",
    "                    vx_ds = float(np.clip(p2[1] - p1[1], -max_step_px, max_step_px))\n",
    "                    if abs(vx_ds) < 0.25:\n",
    "                        vx_ds = min_step_px  # final fallback to small positive step\n",
    "                # clamp & apply decay while coasting so it doesn't accelerate\n",
    "                step_x_ds = float(np.clip(vx_ds, -max_step_px, max_step_px))\n",
    "                vx_ds *= float(vel_decay)\n",
    "\n",
    "                # anchor: advance from last_used_ds (the last measured/predicted point)\n",
    "                base_x_ds, base_y_ds = last_used_ds\n",
    "                # lock Y to recent median (measured-only)\n",
    "                ys_recent = [p[2] for p in list(meas_pts_ds)[-vel_k:]]\n",
    "                next_y_ds = int(np.median(ys_recent)) if enforce_horizontal else base_y_ds\n",
    "\n",
    "                Hds, Wds = adj_ds.shape[:2]\n",
    "                next_x_ds = int(np.clip(base_x_ds + step_x_ds, 0, Wds-1))\n",
    "                last_used_ds = (next_x_ds, next_y_ds)\n",
    "\n",
    "                # map to ORIGINAL\n",
    "                Cx = int(round(next_x_ds * scale_back))\n",
    "                Cy = int(round(next_y_ds * scale_back))\n",
    "                if draw_path:\n",
    "                    trail_orig.append((Cx, Cy))\n",
    "                cv2.circle(vis, (Cx, Cy), 4, (0,165,255), -1)\n",
    "\n",
    "                with open(csv_path, \"a\", newline=\"\") as f:\n",
    "                    csv.writer(f).writerow([frame_idx, 0, 0, 0, 0, \"predicted\"])\n",
    "\n",
    "                if miss_streak > max_predict_frames:\n",
    "                    pass\n",
    "\n",
    "        # draw the full trail on ORIGINAL\n",
    "        if draw_path and len(trail_orig) > 1:\n",
    "            for i in range(1, len(trail_orig)):\n",
    "                cv2.line(vis, trail_orig[i-1], trail_orig[i], (0,255,0), 2)\n",
    "\n",
    "        cv2.putText(vis, f\"Frame {frame_idx}\", (10,26),\n",
    "                    cv2.FONT_HERSHEY_SIMPLEX, 0.7, (255,255,255), 2, cv2.LINE_AA)\n",
    "\n",
    "        # writer (ORIGINAL size, source FPS)\n",
    "        if save_video and writer is None:\n",
    "            fourcc = cv2.VideoWriter_fourcc(*\"mp4v\")\n",
    "            writer = cv2.VideoWriter(str(OUT / \"isolated_annotated.mp4\"), fourcc, fps_out, (W0, H0))\n",
    "        if writer is not None:\n",
    "            writer.write(vis)\n",
    "\n",
    "        # optional live preview\n",
    "        cv2.imshow(\"Isolated (annotated, ORIGINAL size)\", vis)\n",
    "        if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "            break\n",
    "\n",
    "    cap.release()\n",
    "    if writer is not None:\n",
    "        writer.release()\n",
    "    cv2.destroyAllWindows()\n",
    "\n",
    "    print(f\"Done.\\n- Video (original size): {OUT.resolve()}/isolated_annotated.mp4 @ {fps_out:.2f} FPS\\n- CSV: {OUT.resolve()}/detections.csv\")\n",
    "\n",
    "# Run it\n",
    "process_video_with_mask()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a5a47143",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
